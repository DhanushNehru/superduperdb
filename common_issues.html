<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Common issues in AI-data development &mdash; SuperDuperDB  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Full Usage" href="full_usage.html" />
    <link rel="prev" title="Cluster" href="cluster.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SuperDuperDB
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Quick  start</a></li>
<li class="toctree-l1"><a class="reference internal" href="concepts.html">Important Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.html">Encoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_references.html">Using external data references</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="prediction_and_training.html">Deploying predictions and training</a></li>
<li class="toctree-l1"><a class="reference internal" href="watchers.html">Watchers</a></li>
<li class="toctree-l1"><a class="reference internal" href="vector_index.html">Vector Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="cluster.html">Cluster</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Common issues in AI-data development</a></li>
<li class="toctree-l1"><a class="reference internal" href="full_usage.html">Full Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Example notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="source/modules.html">superduperdb-stealth</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperDuperDB</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Common issues in AI-data development</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/common_issues.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="common-issues-in-ai-data-development">
<h1>Common issues in AI-data development<a class="headerlink" href="#common-issues-in-ai-data-development" title="Permalink to this heading"></a></h1>
<p>Traditionally, AI development and databases have lived in separate silo-ed worlds, which
only interact as an afterthought at the point where a production system is required to
apply an AI model to a row or table in a database and store and serve the resulting predictions.</p>
<p>Let’s see how this can play out in practice.</p>
<p>Suppose our situation is as follows:</p>
<ul class="simple">
<li><p>We have data in production populated by users accessing a popular website, and which sends JSON records to MongoDB, with references to web URLs hosted on a separate image server.</p></li>
<li><p>Each record contains some data left behind by users which may be useful for training a classification model.</p></li>
</ul>
<p>Given this data, we would like to accomplish the following:</p>
<ul class="simple">
<li><p>We would like to use our data hosted in MongoDB to train a model to classify images</p></li>
<li><p>We want to use the probabilistic estimates for the classifications in a production scenario</p></li>
</ul>
<p>To do this, we need to be able to implement these high level steps:</p>
<ul class="simple">
<li><p>Access the images and data in a way enabling training a computer-vision classification model</p></li>
<li><p>Train the model on the accessible images and associated labels</p></li>
<li><p>Once the model is trained, deploy it in a way so that incoming user data’s images are classified using his model in as timely a manner as possible.</p></li>
<li><p>Consume the outputs of the model in the functionality of the website</p></li>
</ul>
<p>Pre-2023, this is an extremely arduous task. In order to get a model working using this data, and working with this deployment, we would typically be required to perform something equivalent to the following sequence of tasks (module cloud provider, exact software choices).</p>
<ol class="arabic simple">
<li><p>Download a snapshot of his data from MongoDB and place in an AWS s3 bucket.</p></li>
<li><p>Write a script to run through all of the images mentioned in the BSON records downloaded, and download these to a fast-access hard drive, in elastic block storage</p></li>
<li><p>Write a new script which processes the data downloaded from MongoDB, extracting a dataframe of labels and image URIs in s3. He has to take care not to make bookeeping errors in the process.</p></li>
<li><p>Prepare the model for training, using for example, <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>, to preprocess the images for batching using GPUs, and <code class="docutils literal notranslate"><span class="pre">torch</span></code> for writing the model forward pass.</p></li>
<li><p>To perform training, spin up an EC2 instance, or use AWS Sagemaker. Often the lock-in nature of AWS Sagemaker staves off a large percentage of users. This means defining AWS Cloudformation templates allowing us to easily start a training instance, mount the hard-drive containing the images, and stop the instance with an AWS lambda function after completion.</p></li>
<li><p>If the model is declared sufficient, we move to building a production pipeline. Again, to avoid, vendor lock-in, we might opt for the open-source Apache Airflow. We build a DAG using Airflow, which periodically checks for records which are have yet to be classified in MongoDB, loads data from the database and dumps this into an s3 bucket, downloads the images referred to in this data, loads the model and applies preprocessing to the images, followed by running the model over this data, and finally applying post-processing to the outputs. The classifications are then made human readable, looking up indices in a lookup table we provide. The classifications are finally inserted back to MongoDB, along with the probabilistic estimates from the PyTorch model.</p></li>
<li><p>In performing 6., we are required to provide our model in a way which may be consumed by the production system. We defines a new inference only preprocessor which may be used by the <code class="docutils literal notranslate"><span class="pre">torch</span></code> model, writes a script which re-instantiates his model from the parameters applied in training, and also an additional script responsible for the bookkeeping between the <code class="docutils literal notranslate"><span class="pre">forward</span></code> pass outputs, and the human readable probabilistic predictions.</p></li>
</ol>
<p>This story may sound super familiar to AI developers and data scientists. It can cause delays of months or longer, in deploying even standard use-cases to production. There are indeed tools out there which smoothen the journey to consuming AI through the database - Zen ML, Comet ML, etc.. However, these simply make each step in this complex sequence easier to execute.</p>
<p>What if, by shifting the focus from model centricity, to database centricity, we could simplify matters considerably?</p>
<p>This is where SuperDuperDB comes in. Let’s look at how SuperDuperDB might allow Jim to work:</p>
<ol class="arabic simple">
<li><p>We register the “user” collection in MongoDB with SuperDuperDB, configuring the fact that the URLs point to image
URIs with SuperDuperDB’s inbuilt encoder system. This induces SuperDuperDB to spring into action every time data is updated
in the user collection. SuperDuperDB automatically downloads the URIs to MongoDB and visible to the models installed in
SuperDuperDB, ready for training and inference.</p></li>
<li><p>We program <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> and <code class="docutils literal notranslate"><span class="pre">postprocess</span></code> python functions on his class and wrap these together with the PyTorch model with a single wrapper <code class="docutils literal notranslate"><span class="pre">superduper</span></code>.
We import a SuperDuperDB client, and pass the client and a MongoDB style query <code class="docutils literal notranslate"><span class="pre">q</span> <span class="pre">=</span> <span class="pre">collection.find({'img':</span> <span class="pre">{'$exists':</span> <span class="pre">1}})</span></code>
to the <code class="docutils literal notranslate"><span class="pre">.fit</span></code> method of the wrapped model.</p></li>
<li><p>SuperDuperDB springs into action, uploading the model to SuperDuperDB, and triggering model training on SuperDuperDB’s <code class="docutils literal notranslate"><span class="pre">dask</span></code> worker pool.
Once finished, metrics and model-state are preserved in the configured artifact store.</p></li>
<li><p>Using, one command, <code class="docutils literal notranslate"><span class="pre">model.predict('img',</span> <span class="pre">select=q,</span> <span class="pre">watch=True)</span></code>, Jim installs the model on the user collection,
so that as new data are inserted, the model is evaluated in inference model,
the predictions postprocessed, and human readable outputs are inserted to the user collection.</p></li>
</ol>
<p>With SuperDuperDB setup in this way, and models configurated to operate on the “user” collection,
the deployment reacts automatically to changes in the “user” collection and
model outputs are continuously integrated back into the database.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cluster.html" class="btn btn-neutral float-left" title="Cluster" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="full_usage.html" class="btn btn-neutral float-right" title="Full Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright SuperDuperDB Inc., opensource@superduperdb.com.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>